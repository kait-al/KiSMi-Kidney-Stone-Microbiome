library(zCompositions) # CZM

library(dplyr) # Pipe

library(ggplot2) # Plotting

library(vegan) # envfit and diversity

library(ggsci) # Colours

library(ALDEx2) # ALDEx2

#### Load data ####
#count table = SV by column, samples by row
counts <- read.table("cutadapt_counts.txt", 
                     header = TRUE, row.names = 1, sep = "\t", check.names = FALSE, 
                     quote = "", stringsAsFactors = FALSE)
tax <- read.table("cutadapt_tax.txt", 
                  header = TRUE, row.names = 1, sep = "\t", check.names = FALSE, 
                  quote = "", stringsAsFactors = FALSE)

#### #load meta data table

metadata<-read.table("metadata_oral.txt", header=T, row.names = 1, sep='\t', comment.char = "")

#### Filter ####

# Summarize input counts table
sum(counts) ; dim(counts) ; summary(colSums(counts)) ; summary(rowSums(counts))

# [1] 8101148
# [1]  124 2541
#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#       0       0      10    3188     113 3582585 
#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#    8479   26649   53893   65332   84517  227471 



# Generate a relative abundance table and remove SVs accounting for < 1% of reads in every sample
props <- apply(counts, 1, function(x) {x/sum(x)})
filt_by_props <- counts[, apply(props, 1, max) >= 0.01] 

# calculate frequency minus the final (taxonomy) column
#d.freq <- apply(filt_by_props, 1, function(x){x/sum(x)})
#filtered_tax <- tax[colnames(filt_by_props), ]
#freq <- cbind(filtered_tax,d.freq)
#write.table(freq, file="cutadapt_proportions.txt", sep='\t')

# Summarize output filtered counts table
sum(filt_by_props) ; dim(filt_by_props) ; summary(colSums(filt_by_props)) ; summary(rowSums(filt_by_props))

# [1] 7774969
# [1] 124 164
#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#     349    1783    4272   47408   16371 3582585 
#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#    7515   25845   49766   62701   82909  227164 

# Create filtered data frames
filtered_counts <- counts[rownames(filt_by_props), colnames(filt_by_props)]
filtered_tax <- tax[colnames(filt_by_props), ]
filtered_meta <- metadata[rownames(filt_by_props), ]


#### PCA ####

# Replace zeros, transform, and perform PCA
czm <- cmultRepl(filtered_counts, label = 0, method = "CZM")
clr <- t(apply(czm, 1, function(x) {log(x) - mean(log(x))} ))
pca <- prcomp(clr)

#write.table(t(clr), file="cutadapt_counts_CLR.txt", sep='\t')
# Assemble PCA biplot
sample_positions <- data.frame(pca[["x"]])
asv_positions <- data.frame(pca[["rotation"]])

sample_plot_data <- merge(sample_positions, filtered_meta, by = 0)
rownames(sample_plot_data) <- sample_plot_data$Row.names
sample_plot_data$Row.names <- NULL

sample_plot_data$Cohort<-factor(sample_plot_data$Cohort, levels=c("hc","sf"))
cols <- c("hc" = "#492675", "sf" = "#EF8863")


pca_biplot <- ggplot() +
  geom_point(data = sample_plot_data, aes(x = PC1, y = PC2, colour=Cohort), size = 2.5) +
  stat_ellipse(data = sample_plot_data, aes(x = PC1, y = PC2, colour = Cohort), geom = "polygon", level = 0.95, alpha = 0.025, show.legend = NA, linetype = "dashed") +
  #scale_shape_manual(values = c(21, 24)) +
  scale_colour_manual(values = cols) +
  guides(fill = guide_legend(override.aes = list(shape = 21))) +
  geom_segment(data = asv_positions, aes(x = 0, y = 0, xend = 80 * PC1, yend = 80 * PC2), 
               arrow = arrow(length = unit(1/2, 'picas')),
               color = "black",
               alpha = 0.3) + 
  geom_text(data = asv_positions, aes(x = 80 * PC1, y = 80 * PC2), check_overlap = T,
            label = rownames(asv_positions),
            color = "darkgrey",
            size = 2.5) + 
  labs(x = paste("PC1: ", round(pca$sdev[1]^2/sum(pca$sdev^2),3)), 
       y = paste("PC2: ", round(pca$sdev[2]^2/sum(pca$sdev^2),3))) + 
  theme_linedraw() +
  theme(panel.grid = element_blank())
pca_biplot

fit1 <- envfit(pca, filtered_meta, permutations = 999, na.rm = TRUE)
fit1 #shows factor and categorical data

#################################################################################################################################	
#Taxonomy
#################################################################################################################################	

d<-read.table("filtSV_01_1000_2022.txt", sep="\t", quote="", header=T, row.names=1)
d.1 <- data.frame(d)

# PreOp SF vs HC
d1 <- d.1[, grep("PU", colnames(d.1))]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
d.czm <- cmultRepl(t(d1),  label=0, method="CZM")

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_pu),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_pu)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("Patient","Cohort","Age","Sex","Weight_kg","Height_cm","BMI","PCNL_URS","Stone_Side","Hx_Stone","Num_Stones","UTI","UTI_Recent","Cardiac","Pulmonary","Hypertension","Diabetes","Orthopaedic","Thyroid","IBS_IBD","Crohns","Ulcerative_Colitis","Smoker","Activity","Abx_Recent","StoneType","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker","Other"), drop = FALSE]), permutations = 999, na.rm = TRUE)
#fit1 <- envfit(d.pcx, m.filt, permutations = 999, na.rm = TRUE)
fit1
# 

mm <- model.matrix(~Cohort + Smoker, m.filt)

#This replaces rows that had NAs so aldex.glm doesn't produce an error in later steps
mm <- mm[match(rownames(m.filt),rownames(mm)),]
rownames(mm) <- rownames(mm)

#calculate aldex CLR 
clr <- aldex.clr(d_pu, mm, mc.samples = 128)

#Aldex GLM functions
glm_p <- aldex.glm(clr)
glm_effect <- aldex.glm.effect(clr)
glm_output <- data.frame(glm_p,glm_effect)
write.table(glm_output, file="ALDEx2/glm_tax_SPU_HCU.txt", sep="\t", quote=F, col.names=NA)

####################################################################################################
#stone formers Preop vs OR urine

d.1 <- data.frame(d)
#use only counts table, or remove taxonomy column
d1 <- select(d.1, -"tax.vector")

#
d_sf <- d1[, grep("X1", colnames(d1))]
removeEC <- grep("EC", colnames(d_sf)) 
d_sf <- d_sf[-c(removeEC)]
remove_S <- grep("_S", colnames(d_sf))
d_sf <- d_sf[-c(remove_S)]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_sf),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_sf)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("Patient","SampleTime","Age","Sex","Weight_kg","Height_cm","BMI","PCNL_URS","Stone_Side","Hx_Stone","Num_Stones","UTI","UTI_Recent","Cardiac","Pulmonary","Hypertension","Diabetes","Orthopaedic","Thyroid","IBS_IBD","Crohns","Ulcerative_Colitis","Smoker","Activity","Abx_Recent","StoneType","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker","Other"), drop = FALSE]), permutations = 999, na.rm = TRUE)
#fit1 <- envfit(d.pcx, m.filt, permutations = 999, na.rm = TRUE)
fit1
# 

mm <- model.matrix(~SampleTime + Sex + Smoker + StoneType, m.filt)

#This replaces rows that had NAs so aldex.glm doesn't produce an error in later steps
mm <- mm[match(rownames(m.filt),rownames(mm)),]
rownames(mm) <- rownames(mm)

#calculate aldex CLR 
clr <- aldex.clr(d_sf, mm, mc.samples = 128)

#Aldex GLM functions
glm_p <- aldex.glm(clr)
glm_effect <- aldex.glm.effect(clr)
glm_output <- data.frame(glm_p,glm_effect)
write.table(glm_output, file="ALDEx2/glm_tax_SPU_SOU.txt", sep="\t", quote=F, col.names=NA)

####################################################################################################
#stone formers Stone

d.1 <- data.frame(d)
#use only counts table, or remove taxonomy column
d1 <- select(d.1, -"tax.vector")

#
d_sf <- d1[, grep("X1", colnames(d1))]
removeEC <- grep("EC", colnames(d_sf)) 
d_sf <- d_sf[-c(removeEC)]
removeOU <- grep("_OU", colnames(d_sf))
d_sf <- d_sf[-c(removeOU)]
removePU <- grep("_PU", colnames(d_sf))
d_sf <- d_sf[-c(removePU)]

d_sf <- d_sf[rowSums(d_sf[])>0,]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_sf),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_sf)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("Age","Sex","Weight_kg","Height_cm","BMI","PCNL_URS","Stone_Side","Hx_Stone","Num_Stones","UTI","UTI_Recent","Cardiac","Pulmonary","Hypertension","Diabetes","Thyroid","IBS_IBD","Crohns","Ulcerative_Colitis","Smoker","Activity","Abx_Recent","Stone_major","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker"), drop = FALSE]), permutations = 999, na.rm = TRUE)
fit1
#

####################################################################################################
#Stone formers Stone vs OR-U

d.1 <- data.frame(d)
#use only counts table, or remove taxonomy column
d1 <- select(d.1, -"tax.vector")

#
d_sf <- d1[, grep("X1", colnames(d1))]
removeEC <- grep("EC", colnames(d_sf)) 
d_sf <- d_sf[-c(removeEC)]
removePU <- grep("_PU", colnames(d_sf))
d_sf <- d_sf[-c(removePU)]

d_sf <- d_sf[rowSums(d_sf[])>0,]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_sf),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_sf)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("Patient","Sample","Age","Sex","BMI","UTI","UTI_Recent","Hypertension","Diabetes","Insulin","Sleep_apnea","Race","Smoker","Activity","Abx_Recent","Stone_major","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker"), drop = FALSE]), permutations = 999, na.rm = TRUE)
#fit1 <- envfit(d.pcx, m.filt, permutations = 999, na.rm = TRUE)
fit1
# 

################################################
#EC enzymes
################################################
d<-read.table("picrust2_urinaryKiSMMe/EC_metagenome_out/pred_metagenome_unstrat_rounded_working.txt", sep="\t", quote="", check.names=F, header=T, row.names=1, comment.char="")
d.1 <- data.frame(t(d))

# PreOp SF vs HC
d1 <- d.1[, grep("PU", colnames(d.1))]

d_sf <- d_sf[rowSums(d_sf[])>0,]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_sf),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_sf)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("Cohort","Age","Sex","Weight_kg","Height_cm","BMI","PCNL_URS","Stone_Side","Hx_Stone","Num_Stones","UTI","UTI_Recent","Cardiac","Pulmonary","Hypertension","Diabetes","Orthopaedic","Thyroid","IBS_IBD","Crohns","Ulcerative_Colitis","Smoker","Activity","Abx_Recent","Stone_major","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker","Other"), drop = FALSE]), permutations = 999, na.rm = TRUE)
#fit1 <- envfit(d.pcx, m.filt, permutations = 999, na.rm = TRUE)
fit1
#

#aldex ttest

##########################################################################################
#stone formers Preop vs OR urine
#
d_sf <- d.1[, grep("X1", colnames(d.1))]
removeEC <- grep("EC", colnames(d_sf)) 
d_sf <- d_sf[-c(removeEC)]
remove_S <- grep("_S", colnames(d_sf))
d_sf <- d_sf[-c(remove_S)]

d_sf <- d_sf[rowSums(d_sf[])>0,]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_sf),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_sf)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("SampleTime","Age","Sex","Weight_kg","Height_cm","BMI","PCNL_URS","Stone_Side","Hx_Stone","Num_Stones","UTI","UTI_Recent","Cardiac","Pulmonary","Hypertension","Diabetes","Orthopaedic","Thyroid","IBS_IBD","Crohns","Ulcerative_Colitis","Smoker","Activity","Abx_Recent","StoneType","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker","Other"), drop = FALSE]), permutations = 999, na.rm = TRUE)
#fit1 <- envfit(d.pcx, m.filt, permutations = 999, na.rm = TRUE)
fit1
# 

mm <- model.matrix(~SampleTime + Cardiac + Smoker + StoneType, m.filt)

#This replaces rows that had NAs so aldex.glm doesn't produce an error in later steps
mm <- mm[match(rownames(m.filt),rownames(mm)),]
rownames(mm) <- rownames(mm)

#calculate aldex CLR 
clr <- aldex.clr(d_sf, mm, mc.samples = 128)

#Aldex GLM functions
glm_p <- aldex.glm(clr)
glm_effect <- aldex.glm.effect(clr)
glm_output <- data.frame(glm_p,glm_effect)
write.table(glm_output, file="picrust2_urinaryKiSMMe/Picrust_aldex_ancom/glm_EC_SPU_SOU.txt", sep="\t", quote=F, col.names=NA)

################################################
#Pathways
################################################
d<-read.table("picrust2_urinaryKiSMMe/pathways_out/path_abun_unstrat_rounded_working.txt", sep="\t", quote="", check.names=F, header=T, row.names=1, comment.char="")
d.1 <- data.frame(t(d))

# PreOp SF vs HC
d1 <- d.1[, grep("PU", colnames(d.1))]

d_sf <- d1[rowSums(d1[])>0,]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_sf),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_sf)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("Cohort","Age","Sex","Weight_kg","Height_cm","BMI","PCNL_URS","Stone_Side","Hx_Stone","Num_Stones","UTI","UTI_Recent","Cardiac","Pulmonary","Hypertension","Diabetes","Orthopaedic","Thyroid","IBS_IBD","Crohns","Ulcerative_Colitis","Smoker","Activity","Abx_Recent","Stone_major","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker","Other"), drop = FALSE]), permutations = 999, na.rm = TRUE)
#fit1 <- envfit(d.pcx, m.filt, permutations = 999, na.rm = TRUE)
fit1
# 
#aldex ttest instead of glm, no significant points

##########################################################################################
#stone formers Preop vs OR urine
d_sf <- d.1[, grep("X1", colnames(d.1))]
removeEC <- grep("EC", colnames(d_sf)) 
d_sf <- d_sf[-c(removeEC)]
remove_S <- grep("_S", colnames(d_sf))
d_sf <- d_sf[-c(remove_S)]

d_sf <- d_sf[rowSums(d_sf[])>0,]

# Can't have zeroes. Bayesian-Multiplicative replacement of count zeros
# samples must be as rows
d.czm <- cmultRepl(t(d_sf),  label=0, method="CZM")

#Centre-log-ratio transform the data
d.clr<-apply(d.czm, 2, function(x){log2(x) - mean(log2(x))})

#calculate principal components
#features are COLUMNS
#samples as ROWS
d.pcx <- prcomp(d.clr)

m <- read.table("meta_filt01_1000_2022.txt", header=T, sep='\t', comment.char = "", row.names=1)
m <- data.frame(m)

m.filt <- m[rownames(t(d_sf)), ]

#metadata file has too many columns, remove ones that are irrelevant for the comparison
fit1 <- envfit(d.pcx, data.frame(m.filt[, c("SampleTime","Age","Sex","Weight_kg","Height_cm","BMI","PCNL_URS","Stone_Side","Hx_Stone","Num_Stones","UTI","UTI_Recent","Cardiac","Pulmonary","Hypertension","Diabetes","Orthopaedic","Thyroid","IBS_IBD","Crohns","Ulcerative_Colitis","Smoker","Activity","Abx_Recent","StoneType","Opiate","Statin","ACE_inhibitor","ARB","Allopurinol","SSRI_SNRI","NSAID","Calcium_channel_blocker","Metformin","Benzodiazepine","Birth_control_pill","Diuretic","Alpha_blocker","Other"), drop = FALSE]), permutations = 999, na.rm = TRUE)
#fit1 <- envfit(d.pcx, m.filt, permutations = 999, na.rm = TRUE)
fit1
# 

mm <- model.matrix(~SampleTime + Hx_Stone + Cardiac + Smoker + StoneType, m.filt)

#This replaces rows that had NAs so aldex.glm doesn't produce an error in later steps
mm <- mm[match(rownames(m.filt),rownames(mm)),]
rownames(mm) <- rownames(mm)

#calculate aldex CLR 
clr <- aldex.clr(d_sf, mm, mc.samples = 128)

#Aldex GLM functions
glm_p <- aldex.glm(clr)
glm_effect <- aldex.glm.effect(clr)
glm_output <- data.frame(glm_p,glm_effect)
write.table(glm_output, file="picrust2_urinaryKiSMMe/Picrust_aldex_ancom/glm_paths_SPU_SOU.txt", sep="\t", quote=F, col.names=NA)


#aldex2
d<-t(filtered_counts)
hc<-c("H_450","H_451","H_452","H_453","H_454","H_455","H_456","H_457","H_458","H_459","H_459a","H_460","H_461","H_462","H_463","H_464","H_465","H_466","H_467","H_468","H_469","H_470","H_471","H_472","H_473","H_474","H_475","H_476","H_477","H_478","H_479")
sf<-c("S_101","S_102","S_103","S_104","S_105","S_106","S_107","S_107a","S_108","S_109","S_110","S_111","S_112","S_113","S_114","S_115","S_116","S_117","S_118","S_119","S_120","S_121","S_122","S_123","S_124","S_125","S_126","S_127","S_128","S_129","S_130","S_131","S_132","S_133","S_134","S_135","S_136","S_137","S_138","S_139","S_140","S_141","S_142","S_143","S_144","S_145","S_146","S_147","S_148","S_149","S_150","S_151","S_152","S_153","S_154","S_155","S_156","S_157","S_158","S_159","S_160","S_161","S_162","S_163","S_164","S_165","S_166","S_167","S_168","S_169","S_170","S_171","S_172","S_173","S_174","S_175","S_176","S_177","S_178","S_179","S_180","S_181","S_182","S_183","S_184")

#this will retain the same order as the lists above
# NOTE: ALDEx input must be a DATA FRAME *not* a matrix
aldex.in<-d[,c(hc,sf)]

#Make a vector of conditions. This must be in the same order and the same number as the columns (samples) of the input table (aldex.in)
conds<-c(rep("hc", length(hc)), rep("sf", length(sf)))

#get the clr values
#this is the main ALDEx function for all downstream analyses
#mc.samples=128 is often sufficient
x <- aldex.clr(aldex.in, conds, mc.samples=999, verbose=TRUE)

#perform t-test (both Welches and Wilcoxon, plus a Benjamini-Hochberg multiple test correction)
x.tt <- aldex.ttest(x, conds, paired.test=FALSE)

#estimate effect size and the within and between condition values
#include indiv. samples or not
x.effect <- aldex.effect(x, conds)

#merge the data
x.all <- data.frame(x.tt, x.effect)

#write a .txt with your results
write.table(x.all, file="aldex_hc_sf.txt", sep="\t", quote=F, col.names=NA)
